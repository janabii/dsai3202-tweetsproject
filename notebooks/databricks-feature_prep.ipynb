{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "271e9580-85b1-4603-91fc-e284c16510ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# similar to the labs setup im leaving the feature prepping in a seperate notebook \n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.project60300347.dfs.core.windows.net\",\n",
    "    # Im removing this again bcz github dont allow me to leave it in\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c0815f7-684d-4798-8f4a-b1386253208e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: integer (nullable = true)\n",
      "\n",
      "+----------+---------------+----------+-----+----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|id        |user           |date      |query|text                                                                                                                  |sentiment|\n",
      "+----------+---------------+----------+-----+----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|1467825003|leslierosales  |2009-04-07|NULL | not forever see you soon                                                                                             |0        |\n",
      "|1467853135|andrewofthediaz|2009-04-07|NULL |oh just got all my macheist apps sweet didnt get the espresso serial no though although they said they sent it oh well|0        |\n",
      "|1467934184|wx1901         |2009-04-07|NULL |crap i need more dresses too                                                                                          |0        |\n",
      "|1467963418|Zimily         |2009-04-07|NULL |i had a horrible nightmare last night which affected my sleep now im really tired                                     |0        |\n",
      "|1467971340|TheDCD         |2009-04-07|NULL | hells to the no i only room with                                                                                     |1        |\n",
      "+----------+---------------+----------+-----+----------------------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "tweets_clean = spark.read.format(\"delta\").load(\n",
    "    \"abfss://lakehouse@project60300347.dfs.core.windows.net/processed/tweets_cleaned/\"\n",
    ")\n",
    "\n",
    "tweets_clean.printSchema()\n",
    "tweets_clean.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9064bb79-3832-434f-9fda-e4a93bd03781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------------+---------------+--------------+\n",
      "|date      |total_tweets|positive_tweets|negative_tweets|positive_ratio|\n",
      "+----------+------------+---------------+---------------+--------------+\n",
      "|2009-06-25|25905       |0              |25905          |0.0           |\n",
      "|2009-06-15|82883       |48767          |34116          |0.588         |\n",
      "|2009-06-07|111201      |67577          |43624          |0.608         |\n",
      "|2009-05-03|26436       |15446          |10990          |0.584         |\n",
      "|2009-06-24|2086        |0              |2086           |0.0           |\n",
      "+----------+------------+---------------+---------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# I will create a few aggregations\n",
    "from pyspark.sql.functions import count, sum as _sum, col, round\n",
    "\n",
    "# Daily sentiment counts\n",
    "daily_sentiment = (\n",
    "    tweets_clean.groupBy(\"date\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_tweets\"),\n",
    "        _sum(col(\"sentiment\")).alias(\"positive_tweets\")\n",
    "    )\n",
    "    .withColumn(\"negative_tweets\", col(\"total_tweets\") - col(\"positive_tweets\"))\n",
    "    .withColumn(\"positive_ratio\", round(col(\"positive_tweets\") / col(\"total_tweets\"), 3))\n",
    ")\n",
    "daily_sentiment.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ca1000b-94e3-472b-a38c-a51f64fa3138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+\n",
      "|user           |user_tweet_count|\n",
      "+---------------+----------------+\n",
      "|lost_dog       |549             |\n",
      "|webwoke        |345             |\n",
      "|tweetpet       |310             |\n",
      "|SallytheShizzle|281             |\n",
      "|VioletsCRUK    |279             |\n",
      "+---------------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# top active users\n",
    "top_users = (\n",
    "    tweets_clean.groupBy(\"user\")\n",
    "    .agg(count(\"*\").alias(\"user_tweet_count\"))\n",
    "    .orderBy(col(\"user_tweet_count\").desc())\n",
    ")\n",
    "top_users.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02693c5d-03ce-46ef-b415-cb8c0ebadcd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------------------+\n",
      "|sentiment|sentiment_avg_length|sentiment_tweet_count|\n",
      "+---------+--------------------+---------------------+\n",
      "|0        |64.21               |796985               |\n",
      "|1        |60.64               |794484               |\n",
      "+---------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg tweet length by sentiment \n",
    "from pyspark.sql.functions import length, avg, round, col\n",
    "\n",
    "tweet_length_stats = (\n",
    "    tweets_clean.withColumn(\"tweet_length\", length(col(\"text\")))\n",
    "    .groupBy(\"sentiment\")\n",
    "    .agg(\n",
    "        round(avg(\"tweet_length\"), 2).alias(\"sentiment_avg_length\"),\n",
    "        count(\"*\").alias(\"sentiment_tweet_count\")\n",
    "    )\n",
    "    .orderBy(\"sentiment\")\n",
    ")\n",
    "tweet_length_stats.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a726390-d912-4d83-83e6-39148c6d8943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# after creating all aggregations, i will join them together with the main tweets_clean and save it as features_v1\n",
    "features_v1 = (\n",
    "    tweets_clean\n",
    "    .join(daily_sentiment, on=\"date\", how=\"left\")\n",
    "    .join(top_users, on=\"user\", how=\"left\")\n",
    "    .join(tweet_length_stats, on=\"sentiment\", how=\"left\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc269094-3e5f-4b8c-9fa0-78e7ea421243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: integer (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- total_tweets: long (nullable = true)\n",
      " |-- positive_tweets: long (nullable = true)\n",
      " |-- negative_tweets: long (nullable = true)\n",
      " |-- positive_ratio: double (nullable = true)\n",
      " |-- user_tweet_count: long (nullable = true)\n",
      " |-- sentiment_avg_length: double (nullable = true)\n",
      " |-- sentiment_tweet_count: long (nullable = true)\n",
      "\n",
      "+---------+---------------+----------+----------+-----+----------------------------------------------------------------------------------------------------------------------+------------+---------------+---------------+--------------+----------------+--------------------+---------------------+\n",
      "|sentiment|user           |date      |id        |query|text                                                                                                                  |total_tweets|positive_tweets|negative_tweets|positive_ratio|user_tweet_count|sentiment_avg_length|sentiment_tweet_count|\n",
      "+---------+---------------+----------+----------+-----+----------------------------------------------------------------------------------------------------------------------+------------+---------------+---------------+--------------+----------------+--------------------+---------------------+\n",
      "|1        |LeftCoastMama  |2009-04-07|1468022188|NULL | the mint ones are the fall cookies the spring ones are the chocolatevanilla i think i can still get some mint ones   |20555       |12007          |8548           |0.584         |8               |60.64               |794484               |\n",
      "|0        |andrewofthediaz|2009-04-07|1467853135|NULL |oh just got all my macheist apps sweet didnt get the espresso serial no though although they said they sent it oh well|20555       |12007          |8548           |0.584         |1               |64.21               |796985               |\n",
      "|1        |TheDCD         |2009-04-07|1467971340|NULL | hells to the no i only room with                                                                                     |20555       |12007          |8548           |0.584         |30              |60.64               |794484               |\n",
      "|0        |leslierosales  |2009-04-07|1467825003|NULL | not forever see you soon                                                                                             |20555       |12007          |8548           |0.584         |7               |64.21               |796985               |\n",
      "|0        |wx1901         |2009-04-07|1467934184|NULL |crap i need more dresses too                                                                                          |20555       |12007          |8548           |0.584         |12              |64.21               |796985               |\n",
      "+---------+---------------+----------+----------+-----+----------------------------------------------------------------------------------------------------------------------+------------+---------------+---------------+--------------+----------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "features_v1.printSchema()\n",
    "features_v1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8bc4d8f-3b61-4e1f-986f-2436beeb6345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 1591469\n",
      "root\n",
      " |-- sentiment: integer (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- total_tweets: long (nullable = true)\n",
      " |-- positive_tweets: long (nullable = true)\n",
      " |-- negative_tweets: long (nullable = true)\n",
      " |-- positive_ratio: double (nullable = true)\n",
      " |-- user_tweet_count: long (nullable = true)\n",
      " |-- sentiment_avg_length: double (nullable = true)\n",
      " |-- sentiment_tweet_count: long (nullable = true)\n",
      "\n",
      "\n",
      "Checking for null values in each column:\n",
      "+---------+----+----+---+-------+----+------------+---------------+---------------+--------------+----------------+--------------------+---------------------+\n",
      "|sentiment|user|date|id |query  |text|total_tweets|positive_tweets|negative_tweets|positive_ratio|user_tweet_count|sentiment_avg_length|sentiment_tweet_count|\n",
      "+---------+----+----+---+-------+----+------------+---------------+---------------+--------------+----------------+--------------------+---------------------+\n",
      "|0        |0   |0   |0  |1591469|0   |0           |0              |0              |0             |0               |0                   |0                    |\n",
      "+---------+----+----+---+-------+----+------------+---------------+---------------+--------------+----------------+--------------------+---------------------+\n",
      "\n",
      "\n",
      "Checking value ranges and logical limits:\n",
      "+----------------+----------------+------------------+------------------+--------------------+--------------------+--------------+--------------+\n",
      "|min_total_tweets|max_total_tweets|min_positive_ratio|max_positive_ratio|min_user_tweet_count|max_user_tweet_count|min_avg_length|max_avg_length|\n",
      "+----------------+----------------+------------------+------------------+--------------------+--------------------+--------------+--------------+\n",
      "|             167|          111201|               0.0|             0.644|                   1|                 549|         60.64|         64.21|\n",
      "+----------------+----------------+------------------+------------------+--------------------+--------------------+--------------+--------------+\n",
      "\n",
      "\n",
      "Descriptive statistics overview:\n",
      "+-------+-----------------+-----------------+------------------+-------------------+------------------+--------------------+\n",
      "|summary|     total_tweets|  positive_tweets|   negative_tweets|     positive_ratio|  user_tweet_count|sentiment_avg_length|\n",
      "+-------+-----------------+-----------------+------------------+-------------------+------------------+--------------------+\n",
      "|  count|          1591469|          1591469|           1591469|            1591469|           1591469|             1591469|\n",
      "|   mean| 65715.6109763998| 35714.7961845314|30000.814791868394| 0.4992445426207351|11.507800026265041|  62.427805134703796|\n",
      "| stddev|32946.79987721908|24247.74265223257|13184.882218432986|0.22258765107438963|25.647646053525193|  1.7849983566605057|\n",
      "|    min|              167|                0|                70|                0.0|                 1|               60.64|\n",
      "|    max|           111201|            67577|             45417|              0.644|               549|               64.21|\n",
      "+-------+-----------------+-----------------+------------------+-------------------+------------------+--------------------+\n",
      "\n",
      "\n",
      "Checking for any future-dated rows:\n",
      "Future-dated rows: 0\n",
      "\n",
      "Checking for duplicate tweet IDs:\n",
      "Duplicate tweet_id count: 0\n",
      "\n",
      "Sentiment distribution:\n",
      "+---------+------+\n",
      "|sentiment| count|\n",
      "+---------+------+\n",
      "|        0|796985|\n",
      "|        1|794484|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# before saving the data i will perform quick checks to make sure the data is valid \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, sum as _sum, current_date\n",
    "\n",
    "# 1. Basic structure & row count\n",
    "print(\"Row count:\", features_v1.count())\n",
    "features_v1.printSchema()\n",
    "\n",
    "# 2. Null & empty value checks\n",
    "print(\"\\nChecking for null values in each column:\")\n",
    "null_counts = features_v1.select(\n",
    "    [_sum(col(c).isNull().cast(\"int\")).alias(c) for c in features_v1.columns]\n",
    ")\n",
    "null_counts.show(truncate=False)\n",
    "\n",
    "# 3. Range & logical checks\n",
    "print(\"\\nChecking value ranges and logical limits:\")\n",
    "features_v1.select(\n",
    "    F.min(\"total_tweets\").alias(\"min_total_tweets\"),\n",
    "    F.max(\"total_tweets\").alias(\"max_total_tweets\"),\n",
    "    F.min(\"positive_ratio\").alias(\"min_positive_ratio\"),\n",
    "    F.max(\"positive_ratio\").alias(\"max_positive_ratio\"),\n",
    "    F.min(\"user_tweet_count\").alias(\"min_user_tweet_count\"),\n",
    "    F.max(\"user_tweet_count\").alias(\"max_user_tweet_count\"),\n",
    "    F.min(\"sentiment_avg_length\").alias(\"min_avg_length\"),\n",
    "    F.max(\"sentiment_avg_length\").alias(\"max_avg_length\")\n",
    ").show()\n",
    "\n",
    "# 4. Descriptive statistics overview\n",
    "print(\"\\nDescriptive statistics overview:\")\n",
    "features_v1.describe([\n",
    "    \"total_tweets\", \n",
    "    \"positive_tweets\", \n",
    "    \"negative_tweets\", \n",
    "    \"positive_ratio\", \n",
    "    \"user_tweet_count\", \n",
    "    \"sentiment_avg_length\"\n",
    "]).show()\n",
    "\n",
    "# 5. Date sanity check\n",
    "print(\"\\nChecking for any future-dated rows:\")\n",
    "future_dates = features_v1.filter(F.col(\"date\") > current_date())\n",
    "print(\"Future-dated rows:\", future_dates.count())\n",
    "\n",
    "# 6. Duplicate check based on unique tweet ID\n",
    "print(\"\\nChecking for duplicate tweet IDs:\")\n",
    "dupes = features_v1.groupBy(\"id\").count().filter(\"count > 1\")\n",
    "print(\"Duplicate tweet_id count:\", dupes.count())\n",
    "\n",
    "# 7. Sentiment distribution check\n",
    "print(\"\\nSentiment distribution:\")\n",
    "features_v1.groupBy(\"sentiment\").count().orderBy(\"sentiment\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a01e7815-08a7-474f-a835-c2e484aca9a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# everything looked great in the checks so data is ready to be saved in the gold layer\n",
    "features_v1.write.format(\"delta\").mode(\"overwrite\").save(\n",
    "    \"abfss://lakehouse@project60300347.dfs.core.windows.net/curated/features_v1/\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "project-feat_prep",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
